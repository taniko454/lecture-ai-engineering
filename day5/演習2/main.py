import os
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
import pickle
import time
import great_expectations as gx

class DataLoader:
    """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def load_titanic_data(path="C:\Users\ahmf1\OneDrive\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\lecture-ai-engineering\day5\æ¼”ç¿’2\data\Titanic.csv"):
        """Titanicãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚€"""
        if path:
            return pd.read_csv(path)
        else:
            # ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«
            local_path = "data/Titanic.csv"
            if os.path.exists(local_path):
                return pd.read_csv(local_path)

    @staticmethod
    def preprocess_titanic_data(data):
        """Titanicãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ã™ã‚‹"""
        # å¿…è¦ãªç‰¹å¾´é‡ã‚’é¸æŠ
        data = data.copy()

        # ä¸è¦ãªåˆ—ã‚’å‰Šé™¤
        columns_to_drop = []
        for col in ["PassengerId", "Name", "Ticket", "Cabin"]:
            if col in data.columns:
                columns_to_drop.append(col)

        if columns_to_drop:
            data.drop(columns_to_drop, axis=1, inplace=True)

        # ç›®çš„å¤‰æ•°ã¨ãã®ä»–ã‚’åˆ†é›¢
        if "Survived" in data.columns:
            y = data["Survived"]
            X = data.drop("Survived", axis=1)
            return X, y
        else:
            return data, None


class DataValidator:
    """ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def validate_titanic_data(data):
        """Titanicãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¤œè¨¼"""
        # DataFrameã«å¤‰æ›
        if not isinstance(data, pd.DataFrame):
            return False, ["ãƒ‡ãƒ¼ã‚¿ã¯pd.DataFrameã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"]

        # Great Expectationsã‚’ä½¿ç”¨ã—ãŸãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        try:
            context = gx.get_context()
            data_source = context.data_sources.add_pandas("pandas")
            data_asset = data_source.add_dataframe_asset(name="pd dataframe asset")

            batch_definition = data_asset.add_batch_definition_whole_dataframe(
                "batch definition"
            )
            batch = batch_definition.get_batch(batch_parameters={"dataframe": data})

            results = []

            # å¿…é ˆã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
            required_columns = [
                "Pclass",
                "Sex",
                "Age",
                "SibSp",
                "Parch",
                "Fare",
                "Embarked",
            ]
            missing_columns = [
                col for col in required_columns if col not in data.columns
            ]
            if missing_columns:
                print(f"è­¦å‘Š: ä»¥ä¸‹ã®ã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“: {missing_columns}")
                return False, [{"success": False, "missing_columns": missing_columns}]

            expectations = [
                gx.expectations.ExpectColumnDistinctValuesToBeInSet(
                    column="Pclass", value_set=[1, 2, 3]
                ),
                gx.expectations.ExpectColumnDistinctValuesToBeInSet(
                    column="Sex", value_set=["male", "female"]
                ),
                gx.expectations.ExpectColumnValuesToBeBetween(
                    column="Age", min_value=0, max_value=100
                ),
                gx.expectations.ExpectColumnValuesToBeBetween(
                    column="Fare", min_value=0, max_value=600
                ),
                gx.expectations.ExpectColumnDistinctValuesToBeInSet(
                    column="Embarked", value_set=["C", "Q", "S", ""]
                ),
            ]

            for expectation in expectations:
                result = batch.validate(expectation)
                results.append(result)

            # ã™ã¹ã¦ã®æ¤œè¨¼ãŒæˆåŠŸã—ãŸã‹ãƒã‚§ãƒƒã‚¯
            is_successful = all(result.success for result in results)
            return is_successful, results

        except Exception as e:
            print(f"Great Expectationsæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False, [{"success": False, "error": str(e)}]


class ModelTester:
    """ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def create_preprocessing_pipeline():
        """å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆ"""
        numeric_features = ["Age", "Fare", "SibSp", "Parch"]
        numeric_transformer = Pipeline(
            steps=[
                ("imputer", SimpleImputer(strategy="median")),
                ("scaler", StandardScaler()),
            ]
        )

        categorical_features = ["Pclass", "Sex", "Embarked"]
        categorical_transformer = Pipeline(
            steps=[
                ("imputer", SimpleImputer(strategy="most_frequent")),
                ("onehot", OneHotEncoder(handle_unknown="ignore")),
            ]
        )

        preprocessor = ColumnTransformer(
            transformers=[
                ("num", numeric_transformer, numeric_features),
                ("cat", categorical_transformer, categorical_features),
            ],
            remainder="drop",  # æŒ‡å®šã•ã‚Œã¦ã„ãªã„åˆ—ã¯å‰Šé™¤
        )
        return preprocessor

    @staticmethod
    def train_model(X_train, y_train, model_params=None):
        """ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹"""
        if model_params is None:
            model_params = {"n_estimators": 100, "random_state": 42}

        # å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆ
        preprocessor = ModelTester.create_preprocessing_pipeline()

        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = Pipeline(
            steps=[
                ("preprocessor", preprocessor),
                ("classifier", RandomForestClassifier(**model_params)),
            ]
        )

        # å­¦ç¿’
        model.fit(X_train, y_train)
        return model

    @staticmethod
    def evaluate_model(model, X_test, y_test):
        """ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹"""
        start_time = time.time()
        y_pred = model.predict(X_test)
        inference_time = time.time() - start_time

        accuracy = accuracy_score(y_test, y_pred)
        return {"accuracy": accuracy, "inference_time": inference_time}

    @staticmethod
    def save_model(model, path="models/titanic_model.pkl"):
        model_dir = "models"
        os.makedirs(model_dir, exist_ok=True)
        model_path = os.path.join(model_dir, f"titanic_model.pkl")
        with open(model_path, "wb") as f:
            pickle.dump(model, f)
        return path

    @staticmethod
    def load_model(path="models/titanic_model.pkl"):
        """ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        with open(path, "rb") as f:
            model = pickle.load(f)
        return model

    @staticmethod
    def compare_with_baseline(current_metrics, baseline_threshold=0.75):
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”è¼ƒã™ã‚‹"""
        return current_metrics["accuracy"] >= baseline_threshold


# ãƒ†ã‚¹ãƒˆé–¢æ•°ï¼ˆpytestã§å®Ÿè¡Œå¯èƒ½ï¼‰
def test_data_validation():
    """ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
    data = DataLoader.load_titanic_data()
    X, y = DataLoader.preprocess_titanic_data(data)

    # æ­£å¸¸ãªãƒ‡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
    success, results = DataValidator.validate_titanic_data(X)
    assert success, "ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸ"

    # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
    bad_data = X.copy()
    bad_data.loc[0, "Pclass"] = 5  # æ˜ã‚‰ã‹ã«ç¯„å›²å¤–ã®å€¤
    success, results = DataValidator.validate_titanic_data(bad_data)
    assert not success, "ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯ã§ãã¾ã›ã‚“ã§ã—ãŸ"


def test_model_performance():
    """ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    data = DataLoader.load_titanic_data()
    X, y = DataLoader.preprocess_titanic_data(data)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    model = ModelTester.train_model(X_train, y_train)

    # è©•ä¾¡
    metrics = ModelTester.evaluate_model(model, X_test, y_test)

    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒ
    assert ModelTester.compare_with_baseline(
        metrics, 0.75
    ), f"ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™: {metrics['accuracy']}"

    # æ¨è«–æ™‚é–“ã®ç¢ºèª
    assert (
        metrics["inference_time"] < 1.0
    ), f"æ¨è«–æ™‚é–“ãŒé•·ã™ãã¾ã™: {metrics['inference_time']}ç§’"


if __name__ == "__main__":
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
    data = DataLoader.load_titanic_data()
    X, y = DataLoader.preprocess_titanic_data(data)

    # ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    success, results = DataValidator.validate_titanic_data(X)
    print(f"ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼çµæœ: {'æˆåŠŸ' if success else 'å¤±æ•—'}")
    for result in results:
        # "success": falseã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        if not result["success"]:
            print(f"ç•°å¸¸ã‚¿ã‚¤ãƒ—: {result['expectation_config']['type']}, çµæœ: {result}")
    if not success:
        print("ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        exit(1)

    # ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨è©•ä¾¡
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    model_params = {"n_estimators": 100, "random_state": 42}

    # ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
    model = ModelTester.train_model(X_train, y_train, model_params)
    metrics = ModelTester.evaluate_model(model, X_test, y_test)

    print(f"ç²¾åº¦: {metrics['accuracy']:.4f}")
    print(f"æ¨è«–æ™‚é–“: {metrics['inference_time']:.4f}ç§’")

    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model_path = ModelTester.save_model(model)

    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒ
    baseline_ok = ModelTester.compare_with_baseline(metrics)
    print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ: {'åˆæ ¼' if baseline_ok else 'ä¸åˆæ ¼'}")

def regression_test(current_model, X_test, y_test, baseline_model_path="models/titanic_model.pkl"):
    """
    éå»ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦æ€§èƒ½ãŒåŠ£åŒ–ã—ã¦ã„ãªã„ã‹ã‚’ç¢ºèªã™ã‚‹å·®åˆ†ãƒ†ã‚¹ãƒˆé–¢æ•°ã€‚
    - ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¨éå»ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’æ¯”è¼ƒã€‚
    """
    # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
    current_metrics = ModelTester.evaluate_model(current_model, X_test, y_test)
    current_accuracy = current_metrics["accuracy"]
    print(f"âœ… ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ç²¾åº¦: {current_accuracy:.4f}")

    # éå»ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦è©•ä¾¡
    try:
        baseline_model = ModelTester.load_model(baseline_model_path)
        baseline_metrics = ModelTester.evaluate_model(baseline_model, X_test, y_test)
        baseline_accuracy = baseline_metrics["accuracy"]
        print(f"ğŸ“¦ éå»ãƒ¢ãƒ‡ãƒ«ç²¾åº¦: {baseline_accuracy:.4f}")
    except FileNotFoundError:
        print("âš ï¸ éå»ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚åˆå›ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨è¦‹ãªã—ã¾ã™ã€‚")
        return True  # æ¯”è¼ƒä¸å¯ã ãŒå¤±æ•—ã§ã¯ãªã„

    # ç²¾åº¦ã®å·®åˆ†ãƒã‚§ãƒƒã‚¯
    if current_accuracy >= baseline_accuracy:
        print("âœ… ç²¾åº¦ã«åŠ£åŒ–ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return True
    else:
        print("âŒ ç²¾åº¦ãŒéå»ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚ŠåŠ£åŒ–ã—ã¦ã„ã¾ã™ï¼")
        return False
